(window.webpackJsonp=window.webpackJsonp||[]).push([[98],{396:function(e,t,r){"use strict";r.r(t);var a=r(10),i=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p"),t("div",{staticClass:"table-of-contents"},[t("ul",[t("li",[t("a",{attrs:{href:"#introduction"}},[e._v("Introduction")])]),t("li",[t("a",{attrs:{href:"#features"}},[e._v("Features")])]),t("li",[t("a",{attrs:{href:"#usage"}},[e._v("Usage")])]),t("li",[t("a",{attrs:{href:"#validation"}},[e._v("Validation")])]),t("li",[t("a",{attrs:{href:"#error-handling"}},[e._v("Error Handling")])]),t("li",[t("a",{attrs:{href:"#crud-actions"}},[e._v("CRUD Actions")])]),t("li",[t("a",{attrs:{href:"#edit-import-data"}},[e._v("Edit Import Data")])]),t("li",[t("a",{attrs:{href:"#queue-configuration"}},[e._v("Queue Configuration")])]),t("li",[t("a",{attrs:{href:"#conclusion"}},[e._v("Conclusion")])])])]),t("p"),e._v(" "),t("h3",{attrs:{id:"introduction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),t("p",[e._v("The "),t("strong",[e._v("Data Transfer Module")]),e._v(" allows you to import large amounts of data from CSV files into your application, with support for leads, products, and persons entities. This module leverages Laravel's queue feature for efficient handling of large datasets, ensuring seamless imports even in high-volume scenarios. Additionally, it includes comprehensive validation and error-handling strategies to provide flexibility in dealing with data integrity.")]),e._v(" "),t("h3",{attrs:{id:"features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#features"}},[e._v("#")]),e._v(" Features")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("Queue and Non-Queue Based Import")]),e._v(": Supports importing via Laravel queues for background processing or direct imports for smaller datasets(Without Queue/Sync).")]),e._v(" "),t("li",[t("strong",[e._v("CSV Data Validation")]),e._v(": Validate CSV data before importing to ensure data integrity.")]),e._v(" "),t("li",[t("strong",[e._v("Validation Strategies")]),e._v(": Choose between different strategies to handle data errors ("),t("code",[e._v("Stop on Error")]),e._v(", "),t("code",[e._v("Skip Errors")]),e._v(").")]),e._v(" "),t("li",[t("strong",[e._v("CSV Delimiter Customization")]),e._v(": Support for different CSV delimiters.")]),e._v(" "),t("li",[t("strong",[e._v("Allowed Errors")]),e._v(": Configure the number of allowable errors before the process fails.")]),e._v(" "),t("li",[t("strong",[e._v("CRUD Actions")]),e._v(": Supports Create, Update, and Delete operations.")])]),e._v(" "),t("h3",{attrs:{id:"usage"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#usage"}},[e._v("#")]),e._v(" Usage")]),e._v(" "),t("h4",{attrs:{id:"importing-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#importing-data"}},[e._v("#")]),e._v(" Importing Data")]),e._v(" "),t("p",[e._v("The module can import data for "),t("strong",[e._v("Leads")]),e._v(", "),t("strong",[e._v("Products")]),e._v(", and "),t("strong",[e._v("Persons")]),e._v(" entities from CSV files. You can run the import with or without Laravel's queue feature, depending on your dataset size.")]),e._v(" "),t("h5",{attrs:{id:"import-without-queue"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#import-without-queue"}},[e._v("#")]),e._v(" Import without Queue")]),e._v(" "),t("p",[e._v("If you prefer to import data without utilizing a queue system, you can achieve this by turning off the queue processing functionality.")]),e._v(" "),t("h5",{attrs:{id:"import-with-queue"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#import-with-queue"}},[e._v("#")]),e._v(" Import with Queue")]),e._v(" "),t("p",[e._v("If you prefer to import data utilizing a queue system, you can achieve this by turning on the queue processing functionality.")]),e._v(" "),t("h3",{attrs:{id:"validation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#validation"}},[e._v("#")]),e._v(" Validation")]),e._v(" "),t("p",[e._v("Before importing the CSV data, the module validates the records based on the rules defined for each entity. There are two validation strategies you can choose from:")]),e._v(" "),t("h4",{attrs:{id:"validation-strategies"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#validation-strategies"}},[e._v("#")]),e._v(" Validation Strategies")]),e._v(" "),t("ol",[t("li",[t("strong",[e._v("Stop on Errors")]),e._v(": This strategy will halt the import process when an error is encountered.")]),e._v(" "),t("li",[t("strong",[e._v("Skip Errors")]),e._v(": This strategy skips the rows with errors and continues importing the valid data.")])]),e._v(" "),t("h4",{attrs:{id:"csv-delimiter"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#csv-delimiter"}},[e._v("#")]),e._v(" CSV Delimiter")]),e._v(" "),t("p",[e._v("The default delimiter is a comma ("),t("code",[e._v(",")]),e._v("). If your CSV uses a different delimiter, you can specify it during the import:")]),e._v(" "),t("h3",{attrs:{id:"error-handling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#error-handling"}},[e._v("#")]),e._v(" Error Handling")]),e._v(" "),t("p",[e._v("You can configure the number of allowable errors before the process fails. If the error threshold is met, the import will be terminated and shows to display.\nErrors during the import process are logged, and a detailed report is generated, showing which rows failed and why.")]),e._v(" "),t("h3",{attrs:{id:"crud-actions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#crud-actions"}},[e._v("#")]),e._v(" CRUD Actions")]),e._v(" "),t("p",[e._v("The module supports three main actions during the import process:")]),e._v(" "),t("ol",[t("li",[t("strong",[e._v("Create")]),e._v(": Add new records.")]),e._v(" "),t("li",[t("strong",[e._v("Update")]),e._v(": Update existing records if they match based on the identifier.")]),e._v(" "),t("li",[t("strong",[e._v("Delete")]),e._v(": Remove records based on the provided data.")])]),e._v(" "),t("ul",[t("li",[t("p",[t("strong",[e._v("Create")]),e._v(":"),t("br"),e._v("\nIf records do not exist, new records will be created.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Update")]),e._v(":"),t("br"),e._v("\nIf records exist, they will be updated.")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("Delete")]),e._v(":"),t("br"),e._v("\nIf records exist, they will be deleted, Before importing. If the data does not exist, a validation error will be displayed.")])])]),e._v(" "),t("h3",{attrs:{id:"edit-import-data"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#edit-import-data"}},[e._v("#")]),e._v(" Edit Import Data")]),e._v(" "),t("p",[e._v("Before finalizing the import, you can review and edit the data. The system allows you to preview the imported data and make corrections if needed.")]),e._v(" "),t("h3",{attrs:{id:"queue-configuration"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#queue-configuration"}},[e._v("#")]),e._v(" Queue Configuration")]),e._v(" "),t("p",[e._v("If you are using queues for import, make sure your Laravel queue worker is running:")]),e._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[e._v("php artisan queue:work\n")])])]),t("p",[e._v("You can adjust the queue settings in the "),t("code",[e._v("config/queue.php")]),e._v(" file if needed.")]),e._v(" "),t("h3",{attrs:{id:"conclusion"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[e._v("#")]),e._v(" Conclusion")]),e._v(" "),t("p",[e._v("The "),t("strong",[e._v("Data Transfer Module")]),e._v(" provides a robust solution for importing large datasets into your Krayin application, with flexible options for validation, error handling, and queue-based processing. Whether you're importing millions of records or just a few, this module simplifies the process while ensuring data integrity and flexibility.")])])}),[],!1,null,null,null);t.default=i.exports}}]);